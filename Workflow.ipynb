{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work flow for single cell tracing analysis\n",
    "\n",
    "1. Convert annotations to um units\n",
    "2. (V3d) Resample in 1um steps\n",
    "3. Downsample to 25ums, will also generate indices for endings\n",
    "4. (Console) Transform points according to how the sample was aligned to template (run Transform_points.py under elastix directory)\n",
    "5. Identify points in the corresponding atlas\n",
    "6. Make tiff stack with points only, in full z sections (functional for sample imaged in coronal plane, \n",
    "\n",
    "WIP for samples in horizontal consider that both AP and DV planes were cut...)\n",
    "\n",
    "\n",
    "### update august 2021 for anatomy MS\n",
    "\n",
    "to generate tiff stacks for axons and dendrite as well as region with counts in excel files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tkinter.filedialog as fdialog\n",
    "import Neuron_analysis as na\n",
    "from Neuron_analysis import *\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import SimpleITK as sitk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting pixels to ums....\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "na.points.convert_anno()\n",
    "# repeat for both axons and dendrites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, go to v3d and resample these files in 1um steps\n",
    "Under vaa3d plugin- resample. Repeat for both axons and dendrites\n",
    "\n",
    "Then come back and proceed to next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled annotation step size is 1 um in x y z. downsampling to 25 um. dowmsample ratio is 25.0.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Press Enter to continue... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AL157D_25voxel_trace_1umStepsize.txt\n",
      "Downsampling annotation done.\n",
      "Finding endings of the annotations...\n",
      "There are 81 endings\n",
      "D:/AL157/AL157D_endings.csv\n",
      "File saved in the output directory.\n"
     ]
    }
   ],
   "source": [
    "na.points.downsample_anno()\n",
    "# repeat for both axons and dendrites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, go to console and transform these points\n",
    "use Transform_points.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir = fdialog.askdirectory(title='Please select the input directory')\n",
    "# ie: D:\\2PT electroporation time\\AL066\n",
    "axon= fdialog.askopenfilename(title='Selecte the transformed points for axons')\n",
    "dendrite= fdialog.askopenfilename(title='Selecte the transformed points for dendrites')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files= os.listdir(in_dir)\n",
    "# ending_files= [os.path.join(in_dir,i) for i in files if '_endings' in i]\n",
    "# axon_ending= [i for i in ending_files if 'D_' not in i][0]\n",
    "# dendrite_ending=[i for i in ending_files if 'D_' in i][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir='D:/Complete_points/'\n",
    "mouse_name=na.find_mousename(in_dir)\n",
    "out_name=out_dir+mouse_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### old section\n",
    "\n",
    "mostly for sample 2ara files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to saving tif files..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\skimage\\io\\_io.py:141: UserWarning: D:/Complete_points/AL175_axons.tif is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n"
     ]
    }
   ],
   "source": [
    "points,atlas_name=na.get_pt_natlas(file_type,in_dir,full=False)\n",
    "# reads in the points and get the corresponding atlas(cropped version cus we need to extract the cropped plane from its name)\n",
    "na.find_crop(atlas_name)\n",
    "# extract the cropped sections ie. section 100-394\n",
    "points_full=na.points.refill_section(points,atlas_name)\n",
    "# fills in the missing section by adding the leading slice to the z coordinates of the downsampled points\n",
    "na.atlas.make_tif(points_full, na.fullatlas_name,out_dir+mouse_name, is_axon)\n",
    "# projects the downsampled points(now in full z plane) to a tiff file, now ready to merge with the complete atlas and template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_counts, points_in_atlas=na.points.make_pd(points_full,file_ending,out_name,is_axon)\n",
    "# find the corresponding atlas ID for each point, store in pd datafile with counts for main and ends\n",
    "# also outputs an excel file\n",
    "na.points.make_point_csv(points_full, points_in_atlas,out_name,is_axon)\n",
    "# outputs a csv file with downsampled points and their associated id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "na.points.check_points(points_in_atlas)\n",
    "# check for IDs that are without atlas label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_original= fdialog.askopenfilename(title='Selecte the original resampled points')\n",
    "# asks for the non-downsampled annotation, usually the eswc file that has been converted to um and resampled at 1 um steps\n",
    "# typically in petersen server analysis folder\n",
    "\n",
    "original_withID=na.points.findID_origional(points_original, points_in_atlas,out_name,is_axon)\n",
    "#makes a csv file with original points and their associated id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "what is it that you look for? 484682528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atlas id= 529    484682528\n",
      "Name: id, dtype: int64\n",
      "Name= 529    commissural branch of stria terminalis\n",
      "Name: safe_name, dtype: object\n",
      "Hemisphere= 529    3\n",
      "Name: hemisphere_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "na.whatis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "points,atlas_name=na.get_pt_natlas(file_type,in_dir,full=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-9cf9495d5104>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_crop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0matlas_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Image_registration\\Neuron_analysis\\__init__.py\u001b[0m in \u001b[0;36mfind_crop\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mfinds\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0msection\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mz\u001b[0m \u001b[0mcoronal\u001b[0m \u001b[0mplane\u001b[0m \u001b[0mto\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0mback\u001b[0m \u001b[0mto\u001b[0m \u001b[0moriginal\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mspan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m528\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     For exmaple, for atlas_104-400.mhd, will output 103,128'''\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0mm\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"[0-9]{2,3}.[0-9]{3}\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[0mto_add\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mlead\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_add\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "na.find_crop(atlas_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## update aug 2021 for anatomy MS\n",
    "## for ara2sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "##useful functions\n",
    "\n",
    "def check_points(points_in_atlas):\n",
    "    '''Checks whether all your points' ID is within the atlas labels\n",
    "    Input: matching ID of the points (this is the second output from na.make_pd)\n",
    "    '''\n",
    "    id_inatlas=[]\n",
    "    for x in atlas_labels['region_id']:\n",
    "        intID = int(x)\n",
    "        id_inatlas.append(intID)\n",
    "\n",
    "    # need to format this first ourselves,otherwise problematic for 0 and very large numbers (idk why)    \n",
    "\n",
    "    num_of_zeros = [i for i, x in enumerate(points_in_atlas) if x == 0]\n",
    "    # find the indices for which carries an id =0\n",
    "    \n",
    "    unique_id=set(points_in_atlas)\n",
    "    \n",
    "    for id_inbrain in unique_id:\n",
    "        if id_inbrain not in id_inatlas:\n",
    "            if id_inbrain==0:\n",
    "                print(f'There are {len(num_of_zeros)} points with ID= {id_inbrain}, this index is outside of the brain, consider possible suboptimal image registration')\n",
    "            else: \n",
    "                print(id_inbrain,'this index does not exist in allen reference atlas, see https://github.com/ChristophKirst/ClearMap/issues/37')\n",
    "            warnings.warn('Some points do not have corresponding labels')\n",
    "    return \n",
    "\n",
    "def make_pd(all_points, out_name, atlas_name, axon=1):\n",
    "    ''' \n",
    "    For ara2sample only\n",
    "    Takes in all points (as a list, usually the output of na.refill_section or na.get_pt_natlas ) and formulates a pd structure.\n",
    "    Input: downsampled points (in transformix compatible format), name of corresponding indicies of endings \n",
    "    ouputs: a pandas dataframe with anatomical regions and their corresponding total points count and ending points count, list of atlas ID for each point\n",
    "    \n",
    "    '''\n",
    "                        \n",
    "    image= sitk.ReadImage(atlas_name)\n",
    "    atlas =sitk.GetArrayFromImage(image)\n",
    "        \n",
    "    points_in_atlas=[int(atlas[i[2], i[1],i[0]]) for i in all_points ]\n",
    "    #find an ID for all points\n",
    "\n",
    "    unique_id=set(points_in_atlas)\n",
    "\n",
    "    our_regions=atlas_labels.loc[atlas_labels['region_id'].isin (unique_id)]\n",
    "\n",
    "    id_withcounts=[]\n",
    "    for i in unique_id:\n",
    "        id_withcounts.append([i, points_in_atlas.count(i)])\n",
    "\n",
    "    new_df= pd.DataFrame(id_withcounts, columns=['region_id', 'Total_counts'])\n",
    "    our_regionWcounts=pd.merge(our_regions, new_df)\n",
    "    \n",
    "    if axon==1:\n",
    "        out_name=out_name + 'axons_region_with_counts.xls'\n",
    "    else:\n",
    "        out_name=out_name + 'dendrites_region_with_counts.xls'\n",
    "    \n",
    "    our_regionWcounts.to_excel(out_name,index=None,header=True)\n",
    "\n",
    "    return our_regionWcounts.sort_values(by=['Total_counts']), points_in_atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_labels=atlas_labels=pd.read_csv('D:\\Allenbrainatlas\\ARA_25_micron_mhd_ccf2017\\wraped\\ccf_2017_itksnap_labels.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_axon=0\n",
    "\n",
    "if is_axon==1:\n",
    "    file_type=axon\n",
    "elif is_axon==0:\n",
    "    file_type=dendrite\n",
    "# put 0 if working with dendrites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "points,atlas_name=na.get_pt_natlas(file_type,in_dir)\n",
    "# read points and get path name of the corresponding atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to saving tif files..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\skimage\\io\\_io.py:141: UserWarning: D:/Complete_points/AL142_dendrites.tif is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n"
     ]
    }
   ],
   "source": [
    "if is_axon :\n",
    "    na.atlas.make_tif_1(points, atlas_name,out_dir+mouse_name, is_axon)\n",
    "else:\n",
    "    na.atlas.make_tif(points, atlas_name,out_dir+mouse_name, is_axon)\n",
    "# save points as a tiff file for visualization and overlay\n",
    "# for dendrites, keep the intensities different since...its too cramped up and will look bad!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_in_atlas= na.points.find_point_id(points,atlas_name)\n",
    "# find id of points in corresponding atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 239 points with ID= 0, this index is outside of the brain, consider possible suboptimal image registration\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'warnings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-a710fdb02aca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcheck_points\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoints_in_atlas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#we should only see id=0 as possibility now since now is using the itksnap_wraped atlas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-e5f1fa796690>\u001b[0m in \u001b[0;36mcheck_points\u001b[1;34m(points_in_atlas)\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid_inbrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'this index does not exist in allen reference atlas, see https://github.com/ChristophKirst/ClearMap/issues/37'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Some points do not have corresponding labels'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'warnings' is not defined"
     ]
    }
   ],
   "source": [
    "check_points(points_in_atlas)\n",
    "#we should only see id=0 as possibility now since now is using the itksnap_wraped atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_in_atlas= np.where(points_in_atlas==0, 844, points_in_atlas) \n",
    "# replace id= 0 with 844 (ssp-bfd layer1)\n",
    "\n",
    "if is_axon :\n",
    "    points_in_atlas= np.where(points_in_atlas==800 , 215 , points_in_atlas) \n",
    "    points_in_atlas= np.where(points_in_atlas==1092 , 215 , points_in_atlas)\n",
    "    # replace id= 800 (subependymal zone) and 1092 (lateral ventricle) with 215(caudoputamen)\n",
    "    # especially for AL131\n",
    "\n",
    "check_points(points_in_atlas)\n",
    "# check again to see if 0 disappears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1092 in points_in_atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_counts=na.points.make_pd_ara2sample(points_in_atlas.tolist(),atlas_labels,out_name,is_axon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-45f18c895720>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# typically in petersen server analysis folder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0moriginal_withID\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoints\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindID_origional\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoints_original\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpoints_in_atlas\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mout_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mis_axon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m#makes a csv file with original points and their associated id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Image_registration\\Neuron_analysis\\points.py\u001b[0m in \u001b[0;36mfindID_origional\u001b[1;34m(origional_points, points_in_atlas, out_name, axon)\u001b[0m\n\u001b[0;32m    288\u001b[0m     '''\n\u001b[0;32m    289\u001b[0m     \u001b[1;31m#Load the origional points\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 290\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morigional_points\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0manno\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    291\u001b[0m         \u001b[0manno_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0manno\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m     \u001b[1;31m# heading is stored in anno_data[2], 1st line basically useless\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: ''"
     ]
    }
   ],
   "source": [
    "points_original= fdialog.askopenfilename(title='Selecte the original resampled points')\n",
    "# asks for the non-downsampled annotation, usually the eswc file that has been converted to um and resampled at 1 um steps\n",
    "# typically in petersen server analysis folder\n",
    "\n",
    "original_withID=na.points.findID_origional(points_original, points_in_atlas,out_name,is_axon)\n",
    "#makes a csv file with original points and their associated id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stops here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region_id</th>\n",
       "      <th>acronym</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>AAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ACA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>ACA1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322</th>\n",
       "      <td>1323</td>\n",
       "      <td>vsp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1323</th>\n",
       "      <td>1324</td>\n",
       "      <td>vtd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1324</th>\n",
       "      <td>1325</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1325</th>\n",
       "      <td>1326</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>1327</td>\n",
       "      <td>z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1327 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      region_id acronym\n",
       "0             1      6b\n",
       "1             2     A13\n",
       "2             3     AAA\n",
       "3             4     ACA\n",
       "4             5    ACA1\n",
       "...         ...     ...\n",
       "1322       1323     vsp\n",
       "1323       1324     vtd\n",
       "1324       1325       x\n",
       "1325       1326       y\n",
       "1326       1327       z\n",
       "\n",
       "[1327 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atlas_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([146, 146, 146, ..., 152, 152, 152])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tif(all_points, atlas_name, outname,axon=1):\n",
    "    ''' Project downsampled points on to a tiff stack, useful for overlaping with brain or template (ie, in imageJ)\n",
    "    input: downsampled points in a list containing x y z ordinates as int, directory containing it (this is also the output directory) and whether annotation is axon or not (default True)\n",
    "    example: [[12, 13, 25],\n",
    "             [13, 14, 25],...]\n",
    "    \n",
    "    output: a tiff stack with the same dimensions of the brain/template/atlas mhd files with downsampled points only\n",
    "    each point has a value of the number of occurences (since downsampling combines multiple points as one)\n",
    "    '''\n",
    "        \n",
    "    print('Starting to saving tif files..')\n",
    "    \n",
    "    atlas= sitk.ReadImage(atlas_name)\n",
    "    svolume=np.zeros(atlas.GetSize())\n",
    "    #columns, rows, planes\n",
    "    \n",
    "    zplanes=[]\n",
    "    for i in all_points:\n",
    "        zplanes.append( i[2])\n",
    "    zplanes=np.unique(zplanes)\n",
    "    temp=np.zeros(atlas.GetSize()[0:2])\n",
    "    thepoints=np.asarray(all_points)\n",
    "\n",
    "    for i in zplanes:\n",
    "        index= thepoints[:,2]==i\n",
    "        uindex,counts=np.unique(thepoints[index],return_counts=True, axis=0)\n",
    "        for lines in uindex:\n",
    "            coord1,coord2=lines[0:2]\n",
    "            temp[coord1][coord2]= 1\n",
    "        svolume[:,:,i]=temp #write this in \n",
    "        temp=np.zeros(atlas.GetSize()[0:2]) #reset the empty plane after each z\n",
    "        \n",
    "    \n",
    "    coronal_planetmp= np.swapaxes(np.int16(svolume),0,2)\n",
    "    #for some reason, if just save stuff as tiff, it will save x planes of yz view\n",
    "    #here we shift the 3rd dimension with the first dimension to obtain xy view\n",
    "    if axon==1:\n",
    "        out_name=outname + '_axons.tif'\n",
    "    else:\n",
    "        out_name=outname + '_dendrites.tif'\n",
    "\n",
    "    io.imsave(out_name,coronal_planetmp)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to saving tif files..\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
